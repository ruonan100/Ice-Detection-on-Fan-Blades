{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#最终采用单个时间点来做预测\n",
    "#上交的代码将读入data/15_sample_data.csv文件,由于其只包含15000个点,所以训练结果仅用作示范,没有实际意义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import warnings\n",
    "from numpy import newaxis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.callbacks import Callback\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import h5py\n",
    "\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "\n",
    "def conv2flag(number):\n",
    "    if number == 133:\n",
    "        return 1\n",
    "    elif number == 132:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def conv2Nonelabel(number):\n",
    "    if number == 1:\n",
    "        return 1\n",
    "    elif number == 2:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def conv2Noneflag(number):\n",
    "    if number == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def convert_dataset(x_data, y_data, look_back=60, sweep = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0,len(x_data)-look_back-1,sweep):\n",
    "        a = x_data[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(y_data[i + look_back - 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def drop_nan(dataX, dataY):\n",
    "    dataX_new = []\n",
    "    dataY_new = []\n",
    "    for i in range(dataX.shape[0]):\n",
    "        if str(dataY[i]) == 'nan':\n",
    "            continue\n",
    "        else:\n",
    "            nan_flag = 0\n",
    "            for j in range(dataX.shape[1]):\n",
    "                for k in range(dataX.shape[2]):\n",
    "                    if str(dataX[i,j,k]) == 'nan':\n",
    "                        nan_flag = 1\n",
    "                        break\n",
    "                if nan_flag == 1:\n",
    "                    break\n",
    "            if nan_flag == 0:\n",
    "                dataX_new.append(dataX[i])\n",
    "                dataY_new.append(dataY[i])\n",
    "    return np.array(dataX_new), np.array(dataY_new)\n",
    "\n",
    "def get_dataFrame(num):\n",
    "    #从本地的data文件夹读取训练数据\n",
    "    df1=pd.read_csv('data/'+num+'_data.csv',sep=',') \n",
    "#     df2=pd.read_csv('data/'+num+'data-weather.csv',sep=',',header=None) \n",
    "#     df2.columns = ['temperature','relative_humidity','pressure']\n",
    "#     df =pd.concat([df1,df2], axis = 1) \n",
    "    df = df1\n",
    "    \n",
    "    df['wtur_flt_main'] = df['wtur_flt_main'].diff()\n",
    "    df['wtur_flt_main'] = df['wtur_flt_main'].map(conv2flag)\n",
    "    df['wman_state'] = df['wman_state'].map(conv2Noneflag)\n",
    "    qr = df.query('wtur_flt_main == 1')\n",
    "    x_old = 1\n",
    "    for x in qr.index :\n",
    "        if (x - x_old) > 6000:\n",
    "            #1 for fault surely;2 for health surely; 0 (default) for unsure\n",
    "            df['wtur_flt_main'][(x-1000):x] = 1\n",
    "            df['wtur_flt_main'][(x-6000):(x-4000)] = 2 #-12h to -8h is sure for health\n",
    "        else:\n",
    "            df['wtur_flt_main'][(x-1000):x] = 1 #1000 is for 2 hours (1.94h);        \n",
    "        x_old = x\n",
    "    df['wtur_flt_main'] = df['wtur_flt_main'].map(conv2Nonelabel)    \n",
    "    return df\n",
    "\n",
    "#获取温度差\n",
    "def add_delta_tmp(df, delta):\n",
    "    # delta = 6000: 12h\n",
    "    col = 'tmp_%s'%(delta,)\n",
    "    if col not in df.columns:\n",
    "        df.insert(df.shape[1], col ,1)\n",
    "    df[col] = df[\"environment_tmp\"].diff(delta)\n",
    "    return df\n",
    "\n",
    "# get_data 与 get_data_sub为研究特征选取时所用的函数.\n",
    "def get_data(df):\n",
    "    # v0:包含全部原始的特征值，没有包含天气数据，测试准确率约为80%\n",
    "    look_back = 60\n",
    "    sweep= 2\n",
    "    df_sel = df.drop([\"time\", \"wtid\", 'temperature','relative_humidity',\n",
    "                        'pressure','wman_state','wtur_flt_main'], 1) \n",
    "    \n",
    "    # v1:仅仅包含由人工选取出来的特征值，包含天气数据，取一个时间段,测试准确率约为70%\n",
    "#     look_back = 60\n",
    "#     sweep= 2\n",
    "#     df_sel = df.loc[:,[\"wind_speed\",\n",
    "#             \"generator_speed\",\"power\",\"wind_direction_mean\",\n",
    "#                 \"yaw_position\",\"pitch1_angle\",\"pitch2_angle\",\n",
    "#                        \"pitch3_angle\",                \n",
    "#                 \"environment_tmp\",\"int_tmp\",\n",
    "#                 'temperature','relative_humidity','pressure']]\n",
    "    \n",
    "    #输入新数据进行预测时,应该首先对输入数据按照原来的标准进行归一化\n",
    "    column_min = {}\n",
    "    column_max = {}\n",
    "    for i in range(df_sel.shape[1]):\n",
    "        column_min[list(df_sel)[i]] = np.min(df_sel.iloc[:,i])\n",
    "        column_max[list(df_sel)[i]] = np.max(df_sel.iloc[:,i])\n",
    "        \n",
    "    norm_df = df_sel.iloc[:,:].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    norm_df['wman_state'] = df['wman_state']\n",
    "    \n",
    "    x_data = norm_df.iloc[:,0:norm_df.shape[1]].values\n",
    "    y_data = df.loc[:,'wtur_flt_main'].values # 'wtur_flt_main' 不可加方括号\n",
    "\n",
    "    dataX, dataY = convert_dataset(x_data, y_data, look_back, sweep)\n",
    "    dataX_new, dataY_new = drop_nan(dataX, dataY)\n",
    "    dataX_new = dataX_new[:,:,0:-1]\n",
    "    dataY_new = np_utils.to_categorical(dataY_new)\n",
    "    \n",
    "    end = dataX_new.shape[0]\n",
    "    # end = 2000\n",
    "    spl = 0.7\n",
    "    X_train = dataX_new[0:int(end*spl)]\n",
    "    y_train = dataY_new[0:int(end*spl)]\n",
    "    X_test = dataX_new[int(end*spl):int(end*1)]\n",
    "    y_test = dataY_new[int(end*spl):int(end*1)]\n",
    "    print(\"=== get_data_v0 ===\")\n",
    "    print(\"dimensions of traing data and test data are:\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    return [column_min, column_max, X_train, y_train, X_test, y_test]\n",
    "    \n",
    "#另一类获取训练数据的方式\n",
    "# 先对df进行dropnan处理，再进行时间段切割，理论上来说这样做不够严谨，因为会造成\n",
    "# 原本在时间上没有连在一起的数据连在一起, 但在look-back = 1时这个问题不存在.\n",
    "def get_data_sub(df):\n",
    "#     v0包含全部原始的特征值，没有包含天气数据\n",
    "    look_back = 1\n",
    "    sweep= 1\n",
    "    df = add_delta_tmp(df, 3000)\n",
    "#     df = add_delta_tmp(df, 3000)\n",
    "#     df = add_delta_tmp(df, 1500)\n",
    "    \n",
    "    df_sel = df.dropna()\n",
    "    y_data = df_sel.loc[:,'wtur_flt_main'].values # 'wtur_flt_main' 不可加方括号\n",
    "#     df_sel = df_sel.drop([\"time\", \"wtid\", 'temperature','relative_humidity'\n",
    "#                           ,'pressure','wman_state','wtur_flt_main'], 1)\n",
    "\n",
    "#     df_sel = df_sel.drop([\"time\", \"wtid\", 'temperature','wman_state','wtur_flt_main'], 1)\n",
    "    \n",
    "#     df_sel = df_sel.loc[:,[\"wind_speed\",\n",
    "#             \"generator_speed\",\"power\",\"wind_direction\",\n",
    "#             \"wind_direction_mean\",\n",
    "#             \"yaw_position\",\"yaw_speed\",\n",
    "#             \"pitch1_angle\",\"pitch2_angle\",\"pitch3_angle\", \n",
    "#             \"pitch1_speed\",\"pitch2_speed\",\"pitch3_speed\",\n",
    "#             \"acc_x\",\"acc_y\",\n",
    "#             \"environment_tmp\",\"int_tmp\",\n",
    "#             'relative_humidity']]\n",
    "    \n",
    "#     df_sel = df_sel.loc[:,[\"wind_speed\",\n",
    "#         \"generator_speed\",\"power\",\"wind_direction_mean\",\n",
    "#             \"yaw_position\",\"pitch1_angle\",\"pitch2_angle\",\n",
    "#                    \"pitch3_angle\",                \n",
    "#             \"environment_tmp\",\"int_tmp\",'relative_humidity','pressure']]\n",
    "#     df_sel = df.loc[:,[\"wind_speed\",\n",
    "#     \"power\",\"wind_direction_mean\",\n",
    "#         \"yaw_position\",\"pitch1_angle\",\"pitch2_angle\",\n",
    "#                \"pitch3_angle\",                \n",
    "#         \"environment_tmp\",'relative_humidity','pressure']]\n",
    "\n",
    "#     df_sel = df_sel.loc[:,[\"wind_speed\",\n",
    "#             \"generator_speed\",\"power\",\"wind_direction\",\n",
    "#             \"wind_direction_mean\",\n",
    "#             \"yaw_position\",\n",
    "#             \"pitch1_angle\",\"pitch2_angle\",\"pitch3_angle\", \n",
    "#             \"acc_x\",\"acc_y\",\n",
    "#             \"environment_tmp\",\"int_tmp\"\n",
    "#             ]]\n",
    "\n",
    "#最终的特征选取方案\n",
    "    df_sel = df_sel.loc[:,[\"wind_speed\",\n",
    "        \"generator_speed\",\"power\",\"wind_direction\",\n",
    "        \"wind_direction_mean\",\n",
    "        \"yaw_position\",\n",
    "        \"pitch1_angle\",\"pitch2_angle\",\"pitch3_angle\", \n",
    "        \"environment_tmp\",\"int_tmp\",\n",
    "        \"acc_x\",\"acc_y\",\n",
    "        \"pitch1_ng5_tmp\",\"pitch2_ng5_tmp\",\"pitch3_ng5_tmp\",\n",
    "        \"pitch1_moto_tmp\",\"pitch2_moto_tmp\",\"pitch3_moto_tmp\",\n",
    "        'tmp_3000'\n",
    "        ]]\n",
    "\n",
    "    #输入新数据进行预测时,应该首先对输入数据按照原来的标准进行归一化\n",
    "    column_min = {}\n",
    "    column_max = {}\n",
    "    for i in range(df_sel.shape[1]):\n",
    "        column_min[list(df_sel)[i]] = np.min(df_sel.iloc[:,i])\n",
    "        column_max[list(df_sel)[i]] = np.max(df_sel.iloc[:,i])\n",
    "        \n",
    "    norm_df = df_sel.iloc[:,:].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    \n",
    "    x_data = norm_df.iloc[:,:].values\n",
    "    \n",
    "    dataX, dataY = convert_dataset(x_data, y_data, look_back, sweep)\n",
    "    dataY = np_utils.to_categorical(dataY)\n",
    "    \n",
    "    end = dataX.shape[0]\n",
    "    # end = 2000\n",
    "    spl = 0.7\n",
    "    X_train = dataX[0:int(end*spl)]\n",
    "    y_train = dataY[0:int(end*spl)]\n",
    "    X_test = dataX[int(end*spl):int(end*1)]\n",
    "    y_test = dataY[int(end*spl):int(end*1)]\n",
    "    print(\"=== get_data_sub resultes===\")\n",
    "    print(\"dimensions of traing data and test data are:\")\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    return [column_min, column_max, X_train, y_train, X_test, y_test]\n",
    "\n",
    "#计算混淆举证的四个率\n",
    "def metrics4(y_true1, y_pred1):\n",
    "    y_true = np.zeros(y_true1.shape, dtype = int)\n",
    "    y_pred = np.zeros(y_pred1.shape, dtype = int)\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        y_pred[i] = y_pred1[i]\n",
    "        y_true[i] = y_true1[i]\n",
    "    N = len(y_true)\n",
    "    TP = sum(y_true[:,1] & y_pred[:,1])\n",
    "    TN = sum(y_true[:,0] & y_pred[:,0])\n",
    "    FP = sum(y_true[:,0] & y_pred[:,1])\n",
    "    FN = sum(y_true[:,1] & y_pred[:,0])\n",
    "#     print(TP,TN,FP,FN)\n",
    "    acc = (TP + TN)/N\n",
    "    pre = TP/(TP + FP)\n",
    "    rec = TP/(TP + FN)\n",
    "    F1 = 2*TP/(2*TP + FP + FN)\n",
    "    return [acc, pre, rec, F1]\n",
    "\n",
    "def build_lstm_model(layers,look_back = 60):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(\n",
    "        input_shape=(look_back,layers[0]),\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    opt = Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    start = time.time()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def build_cnn_model(layers, look_back = 60):\n",
    "    model = Sequential()   \n",
    "    \n",
    "    model.add(Convolution2D(\n",
    "        nb_filter=32,\n",
    "        nb_row=8,\n",
    "        nb_col=layers[0],\n",
    "        border_mode='same',     # Padding method\n",
    "        input_shape=(1,look_back,layers[0])))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=(2, 2),\n",
    "    border_mode='same',    # Padding method\n",
    "    ))\n",
    "    \n",
    "    model.add(Convolution2D(64, 8, layers[0], border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), border_mode='same'))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    opt = Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    start = time.time()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def get_edge(model, data):\n",
    "    predicted = model.predict(data)\n",
    "    f=[]\n",
    "    for i in range(predicted.shape[0]):\n",
    "        if predicted[i][0]<predicted[i][1]:\n",
    "            f.append(i)\n",
    "    return f\n",
    "    #consider to get a edge if the state changes hold for 7 points\n",
    "    #这样得到的应该是一个方波模样的东西;所谓的聚类中心,值得就是在那个店开始报故障\n",
    "    \n",
    "def plot_results(predicted_data, true_data,ep):\n",
    "    #if ep%4 == 1:\n",
    "    plt.clf()\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    #fig2 = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    #bx = fig2. add_subplot(111)\n",
    "    #ax.plot(true_data,color='red', label='True Data')\n",
    "    ax.plot(predicted_data,'b*--', label = 'Predicted Break Point')\n",
    "    ax.plot(true_data,'r',label='True Label')\n",
    "    box=ax.get_position()\n",
    "    ax.set_position(box)\n",
    "    plt.legend(loc='upper center',bbox_to_anchor=(0.5,1.15))\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Segmentation Attribute')\n",
    "    #plt.savefig(NUM+'_'+str(ep)+'.png')\n",
    "    #plt.show()\n",
    "    \n",
    "def plot(predicted_data):\n",
    "    plt.clf()\n",
    "    fig = plt.figure(facecolor='white')    \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(predicted_data,'b')\n",
    "    box=ax.get_position()\n",
    "    ax.set_position(box)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train an autoencoder\n",
    "# best traning results for autoencoder: loss ~ 0.54\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "def bulid_autoencoder(layers):\n",
    "    input_img = Input(shape=(layers[0],))\n",
    "    encoded = Dense(layers[1], activation='relu')(input_img)\n",
    "    encoded = Dense(layers[2], activation='relu')(encoded)\n",
    "    \n",
    "    decoded = Dense(layers[1], activation='relu')(encoded)\n",
    "    decoded = Dense(layers[0], activation='relu')(decoded)\n",
    "\n",
    "    return Model(input_img, encoded), Model(input_img, decoded)\n",
    "\n",
    "#训练 autoencoder的代码\n",
    "# if __name__=='__main__':\n",
    "#     print('> Loading data... ')\n",
    "#     df = get_dataFrame('15')\n",
    "#     df_sel = df.drop([\"time\",\"wtid\",'wman_state','wtur_flt_main'], 1)\n",
    "#     df_sel = df_sel.dropna()\n",
    "#     norm_df = df_sel.iloc[:,:].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "\n",
    "#     x_data = norm_df.iloc[:,:].values\n",
    "#     encoder, autoencoder = bulid_autoencoder([x_data[1],1000,15])\n",
    "#     print(encoder.summary())\n",
    "# #     autoencoder.summary()\n",
    "#     autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "#     end = x_data.shape[0]\n",
    "#     spl = 0.7\n",
    "#     x_train = x_data[0:int(end*spl)]\n",
    "#     x_test = x_data[int(end*spl):int(end*1)]\n",
    "\n",
    "#     autoencoder.fit(x_train, x_train, epochs = 10, batch_size=256, shuffle=True,\n",
    "#                    validation_data=(x_test, x_test))\n",
    "#     cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "#     print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "\n",
    "#     x_data_encoded = encoder.predict(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n",
      "=== get_data_sub resultes===\n",
      "dimensions of traing data and test data are:\n",
      "(305, 1, 20)\n",
      "(305, 2)\n",
      "(131, 1, 20)\n",
      "(131, 2)\n",
      "> Data Loaded. Compiling...\n",
      "> Compilation Time :  0.012536287307739258\n"
     ]
    }
   ],
   "source": [
    "# predict modle training\n",
    "if __name__=='__main__':\n",
    "    global_start_time = time.time()    \n",
    "    epochs  = 1\n",
    "    BATCH_SIZE = 10\n",
    "    BATCH_INDEX = 0\n",
    "\n",
    "    print('> Loading data... ')\n",
    "    df = get_dataFrame('15_sample')\n",
    "    \n",
    "    #====LSTM\n",
    "#     column_min, column_max, X_train, y_train, X_test, y_test = get_data(df)\n",
    "    column_min, column_max, X_train, y_train, X_test, y_test = get_data_sub(df)\n",
    "    \n",
    "    print('> Data Loaded. Compiling...')\n",
    "    model = build_lstm_model([X_train.shape[2], 40, 100, y_train.shape[1]], X_train.shape[1] )\n",
    "\n",
    "#     # =====CNN\n",
    "#     column_min, column_max, X_train, y_train, X_test, y_test = get_data(df)\n",
    "#     X_train = np.expand_dims(X_train,axis=1)\n",
    "#     X_test = np.expand_dims(X_test,axis=1)\n",
    "    \n",
    "#     f = open('tmp/column_min_cnn.txt','w')  \n",
    "#     f.write(str(column_min))  \n",
    "#     f.close() \n",
    "#     f = open('tmp/column_max_cnn.txt','w')  \n",
    "#     f.write(str(column_max))  \n",
    "#     f.close() \n",
    "\n",
    "#     print('> Data Loaded. Compiling...')\n",
    "#     model = build_cnn_model([X_train.shape[3], 40, 100, y_train.shape[1]], X_train.shape[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 1\n",
      "Train on 298 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "240/298 [=======================>......] - ETA: 0s - loss: 0.6658 - acc: 0.9208Epoch 00000: val_loss improved from inf to 0.62442, saving model to tmp/lstm_weights_180113_0011.hdf5\n",
      "298/298 [==============================] - 1s - loss: 0.6585 - acc: 0.9362 - val_loss: 0.6244 - val_acc: 1.0000\n",
      "test cost:  0.644090354443 test accuracy:  0.809160292149\n",
      "[acc, pre, rec, F1] is:\n",
      "[0.80916030534351147, nan, 0.0, 0.0]\n",
      "Training duration (s) :  17.771201372146606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4c1e72400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEiCAYAAAAWOs4eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/C9b9BiS8VMmSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4c1e5d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    for ep in range(1,epochs+1):\n",
    "        now = time.strftime(\"%y%m%d_%H%M\")    \n",
    "        filepath='tmp/lstm_weights_%s.hdf5' %(now,)\n",
    "        #filepath='tmp/cnn_weights_%s.hdf5' %(now,)\n",
    "        checkpointer = ModelCheckpoint(filepath, \n",
    "                                       verbose=1, save_best_only=True)\n",
    "        #model.load_weights('tmp/lstm_weights_171223_2003.hdf5')   \n",
    "        \n",
    "        f = open('tmp/column_min.txt_%s'%(now,),'w')   \n",
    "        f.write(str(column_min))  \n",
    "        f.close() \n",
    "        f = open('tmp/column_max.txt_%s' %(now,),'w')  \n",
    "        f.write(str(column_max))  \n",
    "        f.close() \n",
    "        \n",
    "        print('epoch=',ep)\n",
    "        model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        nb_epoch=1,\n",
    "        validation_split=0.02,\n",
    "        callbacks=[checkpointer])\n",
    "        \n",
    "        cost, accuracy = model.evaluate(X_test, y_test, batch_size=y_test.shape[0], verbose=False)\n",
    "        print('test cost: ', cost, 'test accuracy: ', accuracy)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        y_pred_int = np.zeros(y_pred.shape, dtype = int)\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            if y_pred[i][0] < y_pred[i][1]:\n",
    "                y_pred_int[i][1] = 1\n",
    "            else:\n",
    "                y_pred_int[i][0] = 1\n",
    "        print(\"[acc, pre, rec, F1] is:\")\n",
    "        print(metrics4(y_test,y_pred_int))\n",
    "       \n",
    "        y_pred_int = np.zeros(y_pred.shape[0], dtype = int)\n",
    "        fault_pred = np.zeros(y_pred.shape[0], dtype = int)\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            if y_pred[i][1] > 0.55:\n",
    "                y_pred_int[i] = 1\n",
    "        \n",
    "        # 40 for about 5mins\n",
    "        span = 40 * 3\n",
    "        seuil = 0.9\n",
    "        for k in range(span-1,y_pred.shape[0]-1,1):         \n",
    "            if (sum(y_pred_int[k-span+1:k+1]) > seuil*span): \n",
    "                fault_pred[k] = 1\n",
    "\n",
    "        print('Training duration (s) : ', time.time() - global_start_time)\n",
    "        \n",
    "#         plot_results(edg, y_test[:,1],ep)\n",
    "        plt.clf()\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(fault_pred,'b*--', label = 'Predicted Fault Point')\n",
    "        ax.plot(y_test[:,1],'r',label='True Label')\n",
    "        box=ax.get_position()\n",
    "        ax.set_position(box)\n",
    "        plt.legend(loc='upper center',bbox_to_anchor=(0.5,1.15))\n",
    "        plt.xlabel('Index')\n",
    "        plt.ylabel('Segmentation Attribute')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入本地数据,将模型的输出批量写入到数据库中\n",
    "from influxdb import DataFrameClient\n",
    "from influxdb import InfluxDBClient\n",
    "from train_model import *\n",
    "from keras.models import load_model\n",
    "\n",
    "def get_origin_data(num):\n",
    "    df=pd.read_csv('data/'+num+'_data.csv',sep=',') \n",
    "    df['wman_state'] = df['wman_state'].map(conv2Noneflag)\n",
    "       \n",
    "    look_back = 1\n",
    "    sweep= 1\n",
    "    df = add_delta_tmp(df, 3000)\n",
    "    \n",
    "    df_sel = df.dropna()\n",
    "    y_data = df_sel.loc[:,'wtur_flt_main'].values # 'wtur_flt_main' 不可加方括号\n",
    "    time = df_sel.loc[:,'time'].values\n",
    "    \n",
    "    df_sel = df_sel.loc[:,[\"wind_speed\",\n",
    "        \"generator_speed\",\"power\",\"wind_direction\",\n",
    "        \"wind_direction_mean\",\n",
    "        \"yaw_position\",\n",
    "        \"pitch1_angle\",\"pitch2_angle\",\"pitch3_angle\", \n",
    "        \"environment_tmp\",\"int_tmp\",\n",
    "        \"acc_x\",\"acc_y\",\n",
    "        \"pitch1_ng5_tmp\",\"pitch2_ng5_tmp\",\"pitch3_ng5_tmp\",\n",
    "        \"pitch1_moto_tmp\",\"pitch2_moto_tmp\",\"pitch3_moto_tmp\",\n",
    "        'tmp_3000'\n",
    "        ]]\n",
    "        \n",
    "    norm_df = df_sel.iloc[:,:].apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    \n",
    "    x_data = norm_df.iloc[:,:].values\n",
    "    \n",
    "    dataX, dataY = convert_dataset(x_data, y_data, look_back, sweep)\n",
    "    dataY = np_utils.to_categorical(dataY)\n",
    "    \n",
    "    print(\"=== get_origin_data ===\")\n",
    "    print(\"dimensions data are:\")\n",
    "    print(dataX.shape)\n",
    "    print(dataY.shape)\n",
    "    print(time.shape)\n",
    "    return [time, dataX, dataY]\n",
    "\n",
    "db = 'windturbine'\n",
    "client = InfluxDBClient('166.111.38.226', 8086, 'bigdata', '1dW58Qbh4SQX', db )\n",
    "\n",
    "[time, dataX, dataY] = get_origin_data('15_sample')\n",
    "y_pred = model.predict(dataX)\n",
    "y_pred_int = np.zeros(y_pred.shape[0], dtype = int)\n",
    "fault_pred = np.zeros(y_pred.shape[0], dtype = int)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if y_pred[i][1] > 0.55:\n",
    "        y_pred_int[i] = 1\n",
    "\n",
    "# 40 for about 5mins\n",
    "span = 40 * 3\n",
    "seuil = 0.9\n",
    "for k in range(span-1,y_pred.shape[0]-1,1):         \n",
    "    if (sum(y_pred_int[k-span+1:k+1]) > seuil*span): \n",
    "        fault_pred[k] = 1\n",
    "                \n",
    "json_body = []\n",
    "for i in range(dataX.shape[0]):\n",
    "    json_body.append(\n",
    "    {\n",
    "        \"measurement\": \"diagnose_test1\",\n",
    "        \"tags\": {\n",
    "            \"turbine\": '150015'\n",
    "        },\n",
    "        \"time\": time[i],\n",
    "        \"fields\": {\n",
    "            \"fault_prob\": y_pred[i,1],\n",
    "            \"fault_point\": y_pred_int[i],\n",
    "            \"if_alert\": fault_pred[i],\n",
    "        }\n",
    "    }\n",
    "        )\n",
    "    if i % 10000 == 0:\n",
    "        client.write_points(json_body)\n",
    "        json_body = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部分实验记录\n",
    "\n",
    "选取了少部分特征,LSTM结果:    \n",
    "dimensions of traing data and test data are:\n",
    "(43758, 1, 12)\n",
    "(43758, 2)\n",
    "(18754, 1, 12)\n",
    "(18754, 2)\n",
    "\n",
    "epoch= 1\n",
    "Train on 42882 samples, validate on 876 samples\n",
    "Epoch 1/1\n",
    "42860/42882 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.7200Epoch 00000: val_loss improved from inf to 1.01708, saving model to tmp/lstm_weights_171227_2328.hdf5\n",
    "42882/42882 [==============================] - 44s - loss: 0.5432 - acc: 0.7201 - val_loss: 1.0171 - val_acc: 0.0422\n",
    "test cost:  0.465486556292 test accuracy:  0.784845709801\n",
    "        \n",
    "[acc, pre, rec, F1] is:\n",
    "[0.78484589954143114, 0.73717861515440075, 0.98446725406485602, 0.84306328030803934]\n",
    "\n",
    "epoch= 2\n",
    "Train on 42882 samples, validate on 876 samples\n",
    "Epoch 1/1\n",
    "42880/42882 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8202Epoch 00000: val_loss improved from inf to 0.65245, saving model to tmp/lstm_weights_171227_2334.hdf5\n",
    "42882/42882 [==============================] - 42s - loss: 0.3973 - acc: 0.8202 - val_loss: 0.6525 - val_acc: 0.5731\n",
    "test cost:  0.626719236374 test accuracy:  0.607816874981\n",
    "\n",
    "        \n",
    "CNN结果,很差\n",
    "epoch= 1\n",
    "Train on 42882 samples, validate on 876 samples\n",
    "Epoch 1/1\n",
    "42800/42882 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9154Epoch 00000: val_loss improved from inf to 0.24143, saving model to tmp/cnn_weights_171227_2341.hdf5\n",
    "42882/42882 [==============================] - 23s - loss: 0.2120 - acc: 0.9155 - val_loss: 0.2414 - val_acc: 0.9589\n",
    "test cost:  1.66097414494 test accuracy:  0.442892074585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> Loading data... \n",
    "=== get_data_v0 ===\n",
    "dimensions of traing data and test data are:\n",
    "(19733, 60, 26)\n",
    "(19733, 2)\n",
    "(8457, 60, 26)\n",
    "(8457, 2)\n",
    "\n",
    "******LSTM 减少了正常样本的比例后：\n",
    "> Data Loaded. Compiling...\n",
    "> Compilation Time :  0.02680683135986328\n",
    "epoch= 1\n",
    "Train on 19338 samples, validate on 395 samples\n",
    "Epoch 1/1\n",
    "19330/19338 [============================>.] - ETA: 0s - loss: 0.3849 - acc: 0.8139Epoch 00000: val_loss improved from inf to 0.89694, saving model to tmp/lstm_weights_171225_1952.hdf5\n",
    "19338/19338 [==============================] - 262s - loss: 0.3848 - acc: 0.8139 - val_loss: 0.8969 - val_acc: 0.3392\n",
    "test cost:  1.65724658966 test accuracy:  0.517795860767\n",
    "edge:\n",
    "[453, 833, 3790, 5526, 6419, 7919]\n",
    "预测的聚类中心个数：6\n",
    "Training duration (s) :  333.05648970603943\n",
    "\n",
    "    [acc, pre, rec, F1] is:\n",
    "[0.51779590871467418, 0.59496051147047757, 0.62185534591194969, 0.60811070536229095]\n",
    "\n",
    "epoch= 2\n",
    "Train on 19338 samples, validate on 395 samples\n",
    "Epoch 1/1\n",
    "19330/19338 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.8957Epoch 00000: val_loss improved from inf to 0.90058, saving model to tmp/lstm_weights_171225_2004.hdf5\n",
    "19338/19338 [==============================] - 252s - loss: 0.2473 - acc: 0.8957 - val_loss: 0.9006 - val_acc: 0.5519\n",
    "test cost:  2.02002573013 test accuracy:  0.42532813549\n",
    "edge:\n",
    "[957, 1450, 3790, 5380, 5527, 5647, 6037, 6419, 7937]\n",
    "预测的聚类中心个数：9\n",
    "Training duration (s) :  1013.2155096530914\n",
    "\n",
    "epoch= 3\n",
    "Train on 19338 samples, validate on 395 samples\n",
    "Epoch 1/1\n",
    "19330/19338 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9370Epoch 00000: val_loss improved from inf to 1.80654, saving model to tmp/lstm_weights_171225_2009.hdf5\n",
    "19338/19338 [==============================] - 255s - loss: 0.1615 - acc: 0.9371 - val_loss: 1.8065 - val_acc: 0.2000\n",
    "test cost:  1.97060227394 test accuracy:  0.475818872452\n",
    "edge:\n",
    "[832, 3429, 3790, 5348, 6060, 6419, 7970]\n",
    "[acc, pre, rec, F1] is:\n",
    "[0.47581884829135629, 0.56535621632408706, 0.55680031446540879, 0.56104564808396873]\n",
    "*****过拟合？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*****减少了正常样本的比例后 CNN：\n",
    "dimensions of traing data and test data are:\n",
    "(19733,1, 60, 26)\n",
    "(19733, 2)\n",
    "(8457, 1,60, 26)\n",
    "(8457, 2)\n",
    "\n",
    "epoch= 1\n",
    "Train on 19338 samples, validate on 395 samples\n",
    "Epoch 1/1\n",
    "19320/19338 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.7831Epoch 00000: val_loss improved from inf to 1.07892, saving model to tmp/cnn_weights_171225_2018.hdf5\n",
    "19338/19338 [==============================] - 21s - loss: 0.4414 - acc: 0.7832 - val_loss: 1.0789 - val_acc: 0.3696\n",
    "test cost:  0.616311848164 test accuracy:  0.635449826717\n",
    "edge:\n",
    "[829, 3171, 3790, 4741, 5148, 5525, 6419, 7908]\n",
    "预测的聚类中心个数：8\n",
    "[acc, pre, rec, F1] is:\n",
    "[0.63544992314059356, 0.7547649301143583, 0.58372641509433965, 0.65831763271639143]\n",
    "\n",
    "epoch= 2\n",
    "Train on 19338 samples, validate on 395 samples\n",
    "Epoch 1/1\n",
    "19330/19338 [============================>.] - ETA: 0s - loss: 0.3053 - acc: 0.8627Epoch 00000: val_loss improved from inf to 0.81911, saving model to tmp/cnn_weights_171225_2020.hdf5\n",
    "19338/19338 [==============================] - 21s - loss: 0.3053 - acc: 0.8627 - val_loss: 0.8191 - val_acc: 0.5266\n",
    "test cost:  0.609837651253 test accuracy:  0.639351904392\n",
    "edge:\n",
    "[941, 1072, 1430, 3790, 4502, 4759, 5148, 5955, 6419, 7919]\n",
    "预测的聚类中心个数：10\n",
    "\n",
    "epoch= 3\n",
    "Train on 19338 samples, validate on 395 samples\n",
    "Epoch 1/1\n",
    "19280/19338 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.8874Epoch 00000: val_loss improved from inf to 0.67219, saving model to tmp/cnn_weights_171225_2021.hdf5\n",
    "19338/19338 [==============================] - 20s - loss: 0.2551 - acc: 0.8873 - val_loss: 0.6722 - val_acc: 0.5418\n",
    "test cost:  0.578714430332 test accuracy:  0.577627956867\n",
    "edge:\n",
    "[831, 1425, 3790, 5148, 5957, 6419, 7930]\n",
    "\n",
    "[acc, pre, rec, F1] is:\n",
    "[0.57762800047298102, 0.72762762762762767, 0.47621855345911951, 0.57567118080304114]\n",
    "\n",
    "看起来模型很容易就过拟合了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用v0法获取数据，LSTM一次训练结果\n",
    "<br>Loading data... </br>\n",
    "<br>=== get_data_v0 ===</br>\n",
    "<br>dimensions of traing data and test data are:</br>\n",
    "(65233, 1, 26)\n",
    "(65233, 2)\n",
    "(27958, 1, 26)\n",
    "(27958, 2)\n",
    "<br>Data Loaded. Compiling...</br>\n",
    "<br>Compilation Time :  0.014130115509033203</br>\n",
    "<br>epoch= 1</br>\n",
    "<br>Train on 63928 samples, validate on 1305 samples</br>\n",
    "<br>Epoch 1/1</br>\n",
    "<br>63850/63928 [============================>.] - ETA: 0s - loss: 0.4888 - acc: 0.7655Epoch 00000: val_loss improved from inf to 0.83057, saving model to tmp/lstm_weights_171224_2237.hdf5</br>\n",
    "<br>63928/63928 [==============================] - 31s - loss: 0.4888 - acc: 0.7654 - val_loss: 0.8306 - val_acc: 0.2498</br>\n",
    "<br>**test cost:  0.369300633669 test accuracy:  0.844194889069**</br>\n",
    "edge:</br>\n",
    "[6792, 7523, 7875, 12754, 15740, 15950, 21161, 21702, 23158, 25177, 26339, 26827]\n",
    "预测的聚类中心个数：12</br>\n",
    "Training duration (s) :  55.188950061798096</br>\n",
    "![](tmp/lstm1.png)\n",
    "图上很宽的方波应该是邻近故障聚合的结果！每一个蓝星代表着一大段故障点的第一个。需要两大段故障点之间相隔100个点，才会被认为是两段故障。\n",
    "\n",
    "[acc, pre, rec, F1] is:\n",
    "[0.84419486372415764, 0.75967129234824404, 0.88638625056535503, 0.8181514569591718]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用v1法获取数据，CNN一次训练结果\n",
    "<br>=== get_data_v1 ===</br>\n",
    "(29328, 1, 60, 13)\n",
    "(29328, 2)\n",
    "(12570, 1, 60, 13)\n",
    "(12570, 2)\n",
    "<br>epoch= 1</br>\n",
    "Train on 28741 samples, validate on 587 samples</br>\n",
    "<br>Epoch 1/1</br>\n",
    "<br>28720/28741 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.8620Epoch 00000: val_loss improved from inf to 0.63528, saving model to tmp/cnn_weights_171224_2316.hdf5</br>\n",
    "<br>28741/28741 [==============================] - 53s - loss: 0.3215 - acc: 0.8620 - val_loss: 0.6353 - val_acc: 0.5843</br>\n",
    "<br>**test cost:  0.84616535902 test accuracy:  0.720047712326**</br>\n",
    "<br>edge:</br>\n",
    "[851, 1282, 1729, 4616, 5016, 5173, 5383, 5703, 7415, 7629, 8906, 9532, 11946]</br>\n",
    "<br>预测的聚类中心个数：13</br>\n",
    "![](tmp/cnn1.png)\n",
    "\n",
    "[acc, pre, rec, F1] is:\n",
    "[0.72004773269689737, 0.6284591452431636, 0.75432389937106914, 0.6856632425189817]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 采用get_data_sub法获取数据，lstm一次训练结果\n",
    "Train on 31934 samples, validate on 652 samples\n",
    "Epoch 1/1\n",
    "31930/31934 [============================>.] - ETA: 0s - loss: 0.3302 - acc: 0.8635Epoch 00000: val_loss improved from inf to 0.40050, saving model to tmp/lstm_weights_171225_1042.hdf5\n",
    "31934/31934 [==============================] - 497s - loss: 0.3301 - acc: 0.8635 - val_loss: 0.4005 - val_acc: 0.7761\n",
    "<br>***test cost:  0.690901458263 test accuracy:  0.678166747093***<br/>\n",
    "edge:\n",
    "[642, 798, 921, 1281, 1415, 1869, 2388, 3726, 4602, 4730, 6119, 6819, 10282, 10853, 13153, 13449]\n",
    "预测的聚类中心个数：16\n",
    "![](tmp/get_data_sub_lstm1.png)\n",
    "\n",
    "### 采用get_data_sub法获取数据，lstm两次训练结果\n",
    "epoch= 1\n",
    "Train on 31934 samples, validate on 652 samples\n",
    "Epoch 1/1\n",
    "31930/31934 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9346Epoch 00000: val_loss improved from inf to 2.11612, saving model to tmp/lstm_weights_171225_1059.hdf5\n",
    "31934/31934 [==============================] - 496s - loss: 0.1822 - acc: 0.9346 - val_loss: 2.1161 - val_acc: 0.1472\n",
    "test cost:  0.741073668003 test accuracy:  0.705833375454"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
